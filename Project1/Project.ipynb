{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "import urllib.request\n",
    "\n",
    "def get_html(page_url):\n",
    "    \"\"\"Загружает html-текст по заданной ссылке\n",
    "    и обрабатывает исключения.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        page = urllib.request.urlopen(page_url)\n",
    "        return page.read().decode('utf-8')\n",
    "    except Exception:\n",
    "        print('Error at', page_url)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_urls(html_content):\n",
    "    \"\"\"Находит в html-тексте все ссылки.\"\"\"\n",
    "    return re.findall('<a href=\"(.*?)\"', html_content, flags=re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_info(html_content):\n",
    "    \"\"\"Находит в html-тексте информацию об\n",
    "    авторе, заголовке, дате публикации и категории статьи.\n",
    "    \"\"\"\n",
    "    author = re.findall(\n",
    "        '<h3 class=\"author-title author\">'\n",
    "        '<a href=\".*?\" title=\".*?\" rel=\"author\">(.*?)</a>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    if author == '':\n",
    "        author = None\n",
    "    header = re.findall(\n",
    "        '<h1 class=\"entry-title\">(.*?)</h1>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    date = re.findall(\n",
    "        '<time class=\"entry-date updated published\" '\n",
    "        'datetime=\".*?\">(.*?)</time>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    topic = re.findall(\n",
    "        '<span class=\"entry-category\">'\n",
    "        '<a href=\".*?\" rel=\"category tag\">(.*?)</a>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    return author, header, date, topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_text(html_content):\n",
    "    \"\"\"Очищает html-текст от тэгов, приводит в режим чтения,\n",
    "    обрабатывает специальные символы.\n",
    "    \"\"\"\n",
    "    text = re.findall(\n",
    "        '<div class=\"entry-content\">(.*?)</div>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    text = re.sub('<script>.*?</script>', '', text, flags=re.DOTALL)\n",
    "    text = re.sub('<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.DOTALL)\n",
    "    return html.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalogue(s, date):\n",
    "    \"\"\"Создаёт каталог из папок.\"\"\"\n",
    "    year = date.split('.')[2]\n",
    "    directory = '.\\\\Tamlife\\\\%s\\\\%s\\\\%s' % (s, year, date)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mystem(page_id, input_file, output_file1, output_file2):\n",
    "    \"\"\"Создаёт xml- и txt-файлы, размеченные с помощью mystem, из данного.\"\"\"\n",
    "    os.system(''.join([\n",
    "        'C:\\\\Users\\\\ersho\\\\jupyter_github\\\\mystem.exe '\n",
    "        '-c -l -i -d --eng-gr --format xml ',\n",
    "        input_file, os.sep, page_id, '.txt ',\n",
    "        output_file1, os.sep, page_id, '.xml']))\n",
    "    os.system(''.join([\n",
    "        'C:\\\\Users\\\\ersho\\\\jupyter_github\\\\mystem.exe '\n",
    "        '-c -l -i -d --eng-gr ',\n",
    "        input_file, os.sep, page_id, '.txt ',\n",
    "        output_file2, os.sep, page_id, '.txt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv_file(path, author, header, date, topic, url):\n",
    "    \"\"\"Добавляет в csv-файл информацию о статье.\"\"\"\n",
    "    with open('.\\\\Tamlife\\\\metadata.csv', 'a', encoding='utf-8') as f:\n",
    "        year = date.split('.')[2]\n",
    "        f.write(\n",
    "            '%s\\t%s\\t%s\\t%s\\tпублицистика\\t'\n",
    "            '%s\\tнейтральный\\tн-возраст\\tн-уровень\\tрайонная\\t'\n",
    "            '%s\\tТамбовская жизнь\\t'\n",
    "            '%s\\tгазета\\tРоссия\\tТамбовская область\\tru\\n'\n",
    "            % (path, author, header, date, topic, url, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    page_url_base = 'http://tamlife.ru/news'\n",
    "    for page_number in range(1, 194):\n",
    "        page_url = page_url_base\n",
    "        if page_number > 1:\n",
    "            page_url += '/page/%s' % page_number\n",
    "        urls = find_urls(get_html(page_url))\n",
    "        for url in urls:\n",
    "            if re.fullmatch(\n",
    "                    r'http://tamlife\\.ru/news/[A-Za-z]+?/[0-9]+?\\.html',\n",
    "                    url) is not None:\n",
    "                html = get_html(url)\n",
    "                author, header, date, topic = find_info(html)\n",
    "                page_id = re.findall(\n",
    "                    r'.*?/%s([0-9]+?)\\.html' % ''.join(\n",
    "                        reversed(date.split('.'))),\n",
    "                    url)[0]\n",
    "                text = plain_text(html)\n",
    "                path = catalogue('plain', date)\n",
    "                text_file = ''.join([path, os.sep, page_id, '.txt'])\n",
    "                if not os.path.isfile(text_file):\n",
    "                    with open(text_file, 'w', encoding='utf-8') as f:\n",
    "                        f.write(text)\n",
    "                    path_mystem_xml = catalogue('mystem_xml', date)\n",
    "                    path_mystem_plain = catalogue('mystem_plain', date)\n",
    "                    mystem(page_id, path, path_mystem_xml, path_mystem_plain)\n",
    "                    with open(text_file, 'w', encoding='utf-8') as f:\n",
    "                        f.write(\n",
    "                            '@au %s\\n@ti %s\\n@da %s\\n@topic %s\\n@url %s\\n%s'\n",
    "                            % (author, header, date, topic, url, text))\n",
    "                    update_csv_file(\n",
    "                        ''.join([\n",
    "                            path.lstrip('.\\\\'),\n",
    "                            os.sep, page_id, '.txt ']),\n",
    "                        author, header, date, topic, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
