{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "import urllib.request\n",
    "\n",
    "def get_html(page_url):\n",
    "    \"\"\"Загружает html-текст по заданной ссылке\n",
    "    и обрабатывает исключения.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        page = urllib.request.urlopen(page_url)\n",
    "        return page.read().decode('utf-8')\n",
    "    except Exception:\n",
    "        print('Error at', page_url)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_urls(html_content):\n",
    "    \"\"\"Находит в html-тексте все ссылки.\"\"\"\n",
    "    return re.findall('<a href=\"(.*?)\"', html_content, flags=re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_info(html_content):\n",
    "    \"\"\"Находит в html-тексте информацию об\n",
    "    авторе, заголовке, дате публикации и категории статьи.\n",
    "    \"\"\"\n",
    "    author = re.findall(\n",
    "        '<h3 class=\"author-title author\">'\n",
    "        '<a href=\".*?\" title=\".*?\" rel=\"author\">(.*?)</a>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    if author == '':\n",
    "        author = None\n",
    "    header = re.findall(\n",
    "        '<h1 class=\"entry-title\">(.*?)</h1>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    date = re.findall(\n",
    "        '<time class=\"entry-date updated published\" '\n",
    "        'datetime=\".*?\">(.*?)</time>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    topic = re.findall(\n",
    "        '<span class=\"entry-category\">'\n",
    "        '<a href=\".*?\" rel=\"category tag\">(.*?)</a>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    return author, header, date, topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_text(html_content):\n",
    "    \"\"\"Очищает html-текст от тэгов, приводит в режим чтения,\n",
    "    обрабатывает специальные символы.\n",
    "    \"\"\"\n",
    "    text = re.findall(\n",
    "        '<div class=\"entry-content\">(.*?)</div>',\n",
    "        html_content, flags=re.DOTALL)[0]\n",
    "    text = re.sub('<script>.*?</script>', '', text, flags=re.DOTALL)\n",
    "    text = re.sub('<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.DOTALL)\n",
    "    return html.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalogue(s, date):\n",
    "    \"\"\"Создаёт каталог из папок.\"\"\"\n",
    "    year = date.split('.')[2]\n",
    "    directory = '.\\\\Tamlife\\\\%s\\\\%s\\\\%s' % (s, year, date)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mystem(page_id, input_file, output_file1, output_file2):\n",
    "    \"\"\"Создаёт xml- и txt-файлы, размеченные с помощью mystem, из данного.\"\"\"\n",
    "    os.system(''.join([\n",
    "        'C:\\\\Users\\\\ersho\\\\jupyter_github\\\\mystem.exe '\n",
    "        '-c -l -i -d --eng-gr --format xml ',\n",
    "        input_file, os.sep, page_id, '.txt ',\n",
    "        output_file1, os.sep, page_id, '.xml']))\n",
    "    os.system(''.join([\n",
    "        'C:\\\\Users\\\\ersho\\\\jupyter_github\\\\mystem.exe '\n",
    "        '-c -l -i -d --eng-gr ',\n",
    "        input_file, os.sep, page_id, '.txt ',\n",
    "        output_file2, os.sep, page_id, '.txt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv_file(path, author, header, date, topic, url):\n",
    "    \"\"\"Добавляет в csv-файл информацию о статье.\"\"\"\n",
    "    with open('.\\\\Tamlife\\\\metadata.csv', 'a', encoding='utf-8') as f:\n",
    "        year = date.split('.')[2]\n",
    "        f.write(\n",
    "            '%s\\t%s\\t%s\\t%s\\tпублицистика\\t'\n",
    "            '%s\\tнейтральный\\tн-возраст\\tн-уровень\\tрайонная\\t'\n",
    "            '%s\\tТамбовская жизнь\\t'\n",
    "            '%s\\tгазета\\tРоссия\\tТамбовская область\\tru\\n'\n",
    "            % (path, author, header, date, topic, url, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    page_url_base = 'http://tamlife.ru/news'\n",
    "    for page_number in range(1, 194):\n",
    "        page_url = page_url_base\n",
    "        if page_number > 1:\n",
    "            page_url += '/page/%s' % page_number\n",
    "        urls = find_urls(get_html(page_url))\n",
    "        for url in urls:\n",
    "            if re.fullmatch(\n",
    "                    r'http://tamlife\\.ru/news/[A-Za-z]+?/[0-9]+?\\.html',\n",
    "                    url) is not None:\n",
    "                html = get_html(url)\n",
    "                author, header, date, topic = find_info(html)\n",
    "                page_id = re.findall(\n",
    "                    r'.*?/%s([0-9]+?)\\.html' % ''.join(\n",
    "                        reversed(date.split('.'))),\n",
    "                    url)[0]\n",
    "                text = plain_text(html)\n",
    "                path = catalogue('plain', date)\n",
    "                text_file = ''.join([path, os.sep, page_id, '.txt'])\n",
    "                if not os.path.isfile(text_file):\n",
    "                    with open(text_file, 'w', encoding='utf-8') as f:\n",
    "                        f.write(text)\n",
    "                    path_mystem_xml = catalogue('mystem_xml', date)\n",
    "                    path_mystem_plain = catalogue('mystem_plain', date)\n",
    "                    mystem(page_id, path, path_mystem_xml, path_mystem_plain)\n",
    "                    with open(text_file, 'w', encoding='utf-8') as f:\n",
    "                        f.write(\n",
    "                            '@au %s\\n@ti %s\\n@da %s\\n@topic %s\\n@url %s\\n%s'\n",
    "                            % (author, header, date, topic, url, text))\n",
    "                    update_csv_file(\n",
    "                        ''.join([\n",
    "                            path.lstrip('.\\\\'),\n",
    "                            os.sep, page_id, '.txt ']),\n",
    "                        author, header, date, topic, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at http://tamlife.ru/news/sport/2018102612423913128.html\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-9defd275a9f6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m                     url) is not None:\n\u001b[0;32m     12\u001b[0m                 \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mauthor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 page_id = re.findall(\n\u001b[0;32m     15\u001b[0m                     r'.*?/%s([0-9]+?)\\.html' % ''.join(\n",
      "\u001b[1;32m<ipython-input-7-6ce63fc9a658>\u001b[0m in \u001b[0;36mfind_info\u001b[1;34m(html_content)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;34m'<h3 class=\"author-title author\">'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;34m'<a href=\".*?\" title=\".*?\" rel=\"author\">(.*?)</a>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         html_content, flags=re.DOTALL)[0]\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mauthor\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mauthor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
